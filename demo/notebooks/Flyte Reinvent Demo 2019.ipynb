{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flyte + Sagemaker Operators demo\n",
    "Trains a simple XGBoost classifier model for Diabetes Dataset.\n",
    "Dataset Information https://archive.ics.uci.edu/ml/support/diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running task, workflow, and launch plan registration for aws-demo, development, ['workflows'] with version v4.0\n",
      "Registering Task:                workflows.sagemaker_xgboost_hpo.convert_to_sagemaker_csv\n",
      "Registering Task:                workflows.sagemaker_xgboost_hpo.untar_xgboost\n",
      "Registering Task:                workflows.sagemaker_xgboost_hpo.xgtrainer_task\n",
      "Registering Workflow:            workflows.sagemaker_xgboost_hpo.StructuredSagemakerXGBoostHPO\n",
      "Registering Launch Plan:         workflows.sagemaker_xgboost_hpo.fit_lp\n",
      "Registering Task:                workflows.diabetes_xgboost.metrics\n",
      "Registering Task:                workflows.diabetes_xgboost.get_traintest_splitdatabase\n",
      "Registering Task:                workflows.diabetes_xgboost.predict\n",
      "Registering Workflow:            workflows.diabetes_sagemaker_xgboost.DiabetesXGBoostModelOptimizer\n",
      "Registering Launch Plan:         workflows.diabetes_sagemaker_xgboost.DiabetesXGBoostModelOptimizer\n",
      "Registering Task:                workflows.diabetes_xgboost.fit\n",
      "Registering Workflow:            workflows.diabetes_xgboost.DiabetesXGBoostModelTrainer\n",
      "Registering Launch Plan:         workflows.diabetes_xgboost.DiabetesXGBoostModelTrainer\n",
      "Registering Launch Plan:         workflows.sagemaker_xgboost_hpo.StructuredSagemakerXGBoostHPO\n",
      "Registering Task:                workflows.sample.xgtrainer_task\n",
      "Registering Workflow:            workflows.sample.DemoWorkflow\n",
      "Registering Launch Plan:         workflows.sample.DemoWorkflow\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['FLYTE_PLATFORM_URL'] = \"127.0.0.1:8089\"\n",
    "os.environ[\"AWS_PROFILE\"] = \"flytedemo\"\n",
    "project=\"aws-demo\"\n",
    "domain=\"development\"\n",
    "version=\"v4.0\"\n",
    "\n",
    "from flytekit.configuration import set_flyte_config_file\n",
    "os.environ[\"FLYTE_INTERNAL_IMAGE\"] = \"236416911133.dkr.ecr.us-east-1.amazonaws.com/awsdemoplugin:v1.0\"\n",
    "set_flyte_config_file(\"../flyte.config\")\n",
    "os.environ[\"FLYTE_INTERNAL_CONFIGURATION_PATH\"] = \"/app/flyte.config\"\n",
    "\n",
    "from flytekit.clis.sdk_in_container.register import register_all, register_tasks_only\n",
    "register_all(project, domain, [\"workflows\"], version=version, test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART I: Non Hyper parameters tuned Model Training\n",
    "Trains an XGBoost model with static hyper parameters. the model runs as one python task\n",
    "`Detailed Example in` demo/workflows/diabetes_xgboost.py\n",
    "\n",
    "### Flyte supports Schematized inputs / Strictly typed\n",
    "Since we are working with a specific dataset, we will create a strictly typed schema for the dataset.\n",
    "If we wanted a generic data splitter we could use a Generic schema without any column type and name information\n",
    "Example file: https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\n",
    "CSV Columns\n",
    "1. Number of times pregnant\n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "3. Diastolic blood pressure (mm Hg)\n",
    "4. Triceps skin fold thickness (mm)\n",
    "5. 2-Hour serum insulin (mu U/ml)\n",
    "6. Body mass index (weight in kg/(height in m)^2)\n",
    "7. Diabetes pedigree function\n",
    "8. Age (years)\n",
    "9. Class variable (0 or 1)\n",
    "\n",
    "Example Row: 6,148,72,35,0,33.6,0.627,50,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flytekit.sdk.types import Types\n",
    "TYPED_COLUMNS = [\n",
    "    ('#preg', Types.Integer),\n",
    "    ('pgc_2h', Types.Integer),\n",
    "    ('diastolic_bp', Types.Integer),\n",
    "    ('tricep_skin_fold_mm', Types.Integer),\n",
    "    ('serum_insulin_2h', Types.Integer),\n",
    "    ('bmi', Types.Float),\n",
    "    ('diabetes_pedigree', Types.Float),\n",
    "    ('age', Types.Integer),\n",
    "    ('class', Types.Integer),\n",
    "]\n",
    "# the input dataset schema\n",
    "DATASET_SCHEMA = Types.Schema(TYPED_COLUMNS)\n",
    "# the first 8 columns are features\n",
    "FEATURES_SCHEMA = Types.Schema(TYPED_COLUMNS[:8])\n",
    "# the last column is the class\n",
    "CLASSES_SCHEMA = Types.Schema([TYPED_COLUMNS[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to write a Task: Fit Task\n",
    "A Simple python function that takes Features in Some Feature Schema and Classes (columnar vector) and some static hyper parameters and fits an XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflows.diabetes_xgboost import XGBoostModelHyperparams\n",
    "from flytekit.sdk.tasks import python_task, outputs, inputs\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "@inputs(x=FEATURES_SCHEMA, y=CLASSES_SCHEMA, hyperparams=Types.Generic)  # TODO support arbitrary jsonifiable classes\n",
    "@outputs(model=Types.Blob)\n",
    "@python_task(cache_version='2.0', cache=True, memory_limit=\"200Mi\")\n",
    "def fit(ctx, x, y, hyperparams, model):\n",
    "    \"\"\"\n",
    "    This function takes the given input features and their corresponding classes to train a XGBClassifier.\n",
    "    NOTE: We have simplified the number of hyper parameters we take for demo purposes\n",
    "    \"\"\"\n",
    "    with x as r:\n",
    "        x_df = r.read()\n",
    "    with y as r:\n",
    "        y_df = r.read()\n",
    "\n",
    "    hp = XGBoostModelHyperparams.from_dict(hyperparams)\n",
    "    # fit model no training data\n",
    "    m = XGBClassifier(n_jobs=hp.n_jobs, max_depth=hp.max_depth, n_estimators=hp.n_estimators, booster=hp.booster,\n",
    "                      objective=hp.objective, learning_rate=hp.learning_rate)\n",
    "    m.fit(x_df, y_df)\n",
    "\n",
    "    # TODO model Blob should be a file like object\n",
    "    fname = \"model.pkl\"\n",
    "    with open(fname, \"wb\") as f:\n",
    "        pickle.dump(m, f)\n",
    "    model.set(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to write a workflow: Workflow (pipeline)\n",
    "Creates a pipeline that\n",
    "`Gets Data & Split into training and validation`\n",
    " -> `Fit`\n",
    " -> `Predict`\n",
    " -> `Compute metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flytekit.sdk.workflow import workflow_class, Output, Input\n",
    "from workflows.diabetes_xgboost import get_traintest_splitdatabase, predict, metrics, fit\n",
    "from workflows.sagemaker_xgboost_hpo import fit_lp as SagemakerXGBoostHPO\n",
    "    \n",
    "@workflow_class\n",
    "class DiabetesXGBoostModelTrainer(object):\n",
    "    \"\"\"\n",
    "    This pipeline trains an XGBoost mode for any given dataset that matches the schema as specified in\n",
    "    https://github.com/jbrownlee/Datasets/blob/master/pima-indians-diabetes.names.\n",
    "    \"\"\"\n",
    "\n",
    "    # Inputs dataset, fraction of the dataset to be split out for validations and seed to use to perform the split\n",
    "    dataset = Input(Types.CSV, default=Types.CSV.create_at_known_location(\n",
    "        \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"),\n",
    "                    help=\"A CSV File that matches the format https://github.com/jbrownlee/Datasets/blob/master/pima-indians-diabetes.names\")\n",
    "\n",
    "    test_split_ratio = Input(Types.Float, default=0.33, help=\"Ratio of how much should be test to Train\")\n",
    "    seed = Input(Types.Integer, default=7, help=\"Seed to use for splitting.\")\n",
    "\n",
    "    # Split the dataset\n",
    "    split = get_traintest_splitdatabase(dataset=dataset, seed=seed, test_split_ratio=test_split_ratio)\n",
    "\n",
    "    # XGBoost training task\n",
    "    #fit_task = fit(x=split.outputs.x_train, y=split.outputs.y_train, hyperparams=XGBoostModelHyperparams(max_depth=4,).to_dict())\n",
    "    \n",
    "    # This is the alternate task that performs Hyper parameter tuning\n",
    "    fit_task = SagemakerXGBoostHPO(train_data=split.outputs.x_train, train_target=split.outputs.y_train, validation_data=split.outputs.x_test, validation_target=split.outputs.y_test)\n",
    "    \n",
    "    # Prediction task\n",
    "    predicted = predict(model_ser=fit_task.outputs.model, x=split.outputs.x_test)\n",
    "    \n",
    "    # Score calculation task\n",
    "    score_task = metrics(predictions=predicted.outputs.predictions, y=split.outputs.y_test)\n",
    "\n",
    "    # Outputs: joblib seralized model and accuracy of the model\n",
    "    model = Output(fit_task.outputs.model, sdk_type=Types.Blob)\n",
    "    accuracy = Output(score_task.outputs.accuracy, sdk_type=Types.Float)\n",
    "\n",
    "DiabetesXGBoostModelTrainer_lp = DiabetesXGBoostModelTrainer.create_launch_plan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let us register the workflow\n",
    "We will skip talking about launch plans for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lp:aws-demo:development:DiabetesXGBoostModelTrainer_HPO:v4.0'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DiabetesXGBoostModelTrainer.register(project, domain, \"DiabetesXGBoostModelTrainer\", version)\n",
    "#DiabetesXGBoostModelTrainer_lp.register(project, domain, \"DiabetesXGBoostModelTrainer\", version)\n",
    "DiabetesXGBoostModelTrainer.register(project, domain, \"DiabetesXGBoostModelTrainer_HPO\", version)\n",
    "DiabetesXGBoostModelTrainer_lp.register(project, domain, \"DiabetesXGBoostModelTrainer_HPO\", version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets start an execution\n",
    "We will use the dataset available here \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started execution: http://ac9bf898207d811ea83c716283142b67-1154220099.us-east-1.elb.amazonaws.com/console/projects/aws-demo/domains/development/executions/f1eaf18a93dbd4395b02\n"
     ]
    }
   ],
   "source": [
    "execution = DiabetesXGBoostModelTrainer_lp.execute(project, domain, inputs={\n",
    "    \"dataset\": \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"})\n",
    "print(\"Started execution: http://ac9bf898207d811ea83c716283142b67-1154220099.us-east-1.elb.amazonaws.com/console/projects/{}/domains/{}/executions/{}\".format(project, domain, execution.id.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets wait for the execution to complete and retrieve information\n",
    "The execution is unique identified with the name given. Lets print the outputs received and the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow produced outputs => dict_keys(['accuracy', 'model'])\n",
      "Model Training computed accuracy => 66.14173228346458\n"
     ]
    }
   ],
   "source": [
    "from flytekit.common.workflow_execution import SdkWorkflowExecution\n",
    "execution = SdkWorkflowExecution.fetch(project, domain, execution.id.name)\n",
    "\n",
    "execution.wait_for_completion()\n",
    "print(\"Workflow produced outputs => {}\".format(execution.outputs.keys()))\n",
    "\n",
    "print(\"Model Training computed accuracy => {}\".format(execution.outputs[\"accuracy\"]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets retrieve the model and we can run predictions\n",
    "Flyte stores the model as a blob and the API provides a handy way of retrieveing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded the generated model.\n",
      "[17:02:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Model {} loaded, ready to predict!\n"
     ]
    }
   ],
   "source": [
    "# Download the model locally to run predictions\n",
    "execution.outputs[\"model\"].download(\"model\", overwrite=True)\n",
    "print(\"Downloaded the generated model.\")\n",
    "with open(\"model\", \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "print(\"Model {} loaded, ready to predict!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets use the model for prediction\n",
    "Flyte makes it easy to retrieve the model as shown in previous cell, and now it can be loaded in this cases using pickle and lets perform a sample classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 1, diabetes likely - 86.44155859947205%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'#preg': [6], 'pgc_2h': [148], 'diastolic_bp': [72], 'tricep_skin_fold_mm': [35], 'serum_insulin_2h': [0], 'bmi': [33.6], 'diabetes_pedigree': [0.627], 'age': [50]})\n",
    "booster = model\n",
    "if not isinstance(model, xgb.core.Booster):\n",
    "    booster = model.get_booster()\n",
    "v = booster.predict(data=xgb.DMatrix(df, feature_names=booster.feature_names))\n",
    "if v > 0.75:\n",
    "    print(\"Class: 1, diabetes likely - {}%\".format(v[0]*100))\n",
    "else:\n",
    "    print(\"Class: 0, diabetes unlikely {}%\".format(v[0]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHY did they run so fast?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awsdemo",
   "language": "python",
   "name": "awsdemo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
